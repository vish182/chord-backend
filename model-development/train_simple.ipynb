{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3360513, 24), (3360513,))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "all_chroma_vectors = np.load('data/01_all_chroma_vectors.npy')\n",
    "all_chord_labels = np.load('data/01_all_chord_labels.npy')\n",
    "all_chroma_vectors.shape, all_chord_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bit of analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "counts, _, _ = plt.hist(all_chord_labels, bins=list(set(all_chord_labels)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22911.0, 408735.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(counts), max(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since minimum counts is ~20000, w/c is already a lot, we can get maybe around 1000 from each class as test set, 4000 from each class as validation set on 5 different splits, splits w/o overlapping data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([5, 6, 3, 7, 4, 9, 8, 1, 2],\n",
       " [55, 66, 33, 77, 44, 99, 88, 11, 22],\n",
       " [4, 5, 2, 6, 3, 8, 7, 0, 1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy.random import default_rng\n",
    "\n",
    "_SEED = 0\n",
    "\n",
    "# test; must always return same result in successive runs\n",
    "x = [1,2,3,4,5,6,7,8,9]\n",
    "rng = default_rng(seed=_SEED)\n",
    "rng.shuffle(x)\n",
    "\n",
    "# re-seeding allows to get similar shuffles for diff.arrays\n",
    "y = [11,22,33,44,55,66,77,88,99]\n",
    "rng = default_rng(seed=_SEED)\n",
    "rng.shuffle(y)\n",
    "\n",
    "z = [0,1,2,3,4,5,6,7,8]\n",
    "rng = default_rng(seed=_SEED)\n",
    "rng.shuffle(z)\n",
    "\n",
    "x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([5, 6, 3, 7, 4, 9, 8, 1, 2],\n",
       " [55, 66, 33, 77, 44, 99, 88, 11, 22],\n",
       " [4, 5, 2, 6, 3, 8, 7, 0, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def shuffle_set(array_set):\n",
    "    \"\"\" Shuffle in unison all arrays in array_set \"\"\"\n",
    "    for arr in array_set:\n",
    "        rng = default_rng(seed=_SEED)\n",
    "        rng.shuffle(arr)\n",
    "    \n",
    "    return array_set\n",
    "\n",
    "x = [1,2,3,4,5,6,7,8,9]\n",
    "y = [11,22,33,44,55,66,77,88,99]\n",
    "z = [0,1,2,3,4,5,6,7,8]\n",
    "x,y,z = shuffle_set((x,y,z))\n",
    "\n",
    "x,y,z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll shuffle first before splitting to add some randomness in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "_NUM_TEST_PER_CLASS = 1 #1000\n",
    "_NUM_VAL_PER_CLASS = 4 #4000\n",
    "_NUM_VAL_SPLITS = 5\n",
    "\n",
    "class QueueData():\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.st_ix = 0\n",
    "    \n",
    "    def take(self, num):\n",
    "        st, ed = self.st_ix, self.st_ix+num\n",
    "        queue_out = tuple(data[st:ed] for data in self.dataset)\n",
    "        self.st_ix = ed\n",
    "        return queue_out\n",
    "    \n",
    "    def flush(self):\n",
    "        st, ed = self.st_ix, len(self.dataset[0])\n",
    "        queue_out = tuple(data[st:ed] for data in self.dataset)\n",
    "        return queue_out\n",
    "\n",
    "class SplitData():\n",
    "    def __init__(self, feats=None, labels=None):\n",
    "        self.feats = feats\n",
    "        self.labels = labels\n",
    "        \n",
    "    def push(self, feats, labels):\n",
    "        assert(len(feats)==len(labels))\n",
    "        if self.feats is None:\n",
    "            self.feats = feats\n",
    "        else:\n",
    "            self.feats = np.concatenate((self.feats, feats))\n",
    "        \n",
    "        if self.labels is None:\n",
    "            self.labels = labels\n",
    "        else:\n",
    "            self.labels = np.concatenate((self.labels, labels))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    @property\n",
    "    def shape(self):\n",
    "        return (self.feats.shape, self.labels.shape)\n",
    "\n",
    "def get_splits(feats, labels, validate=True):\n",
    "    \"\"\" Return training, validation, and test sets \"\"\"\n",
    "    classes = list(set(labels))\n",
    "    classes.sort()\n",
    "    \n",
    "    if validate:\n",
    "        hist, _ = np.histogram(labels, bins=classes)\n",
    "        assert(min(hist) >= (_NUM_TEST_PER_CLASS + (_NUM_VAL_SPLITS*_NUM_VAL_PER_CLASS)))\n",
    "    \n",
    "    test_split = SplitData()\n",
    "    val_splits = [SplitData() for i in range(_NUM_VAL_SPLITS)]\n",
    "    train_split = SplitData()\n",
    "    \n",
    "    for cls in classes:\n",
    "        mask = (labels==cls)\n",
    "        queue = QueueData(dataset=(feats[mask], labels[mask]))\n",
    "        \n",
    "        test_split.push(*queue.take(_NUM_TEST_PER_CLASS))\n",
    "        for ix in range(_NUM_VAL_SPLITS):\n",
    "            val_splits[ix].push(*queue.take(_NUM_VAL_PER_CLASS))\n",
    "        train_split.push(*queue.flush())\n",
    "\n",
    "    return train_split, val_splits, test_split\n",
    "\n",
    "train_split, val_splits, test_split = get_splits(all_chroma_vectors[:100], all_chord_labels[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((58, 24), (58,))\n",
      "((8, 24), (8,))\n",
      "((8, 24), (8,))\n",
      "((8, 24), (8,))\n",
      "((8, 24), (8,))\n",
      "((8, 24), (8,))\n",
      "((2, 24), (2,))\n"
     ]
    }
   ],
   "source": [
    "print(train_split.shape)\n",
    "for val_split in val_splits:\n",
    "    print(val_split.shape)\n",
    "print(test_split.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((2835513, 24), (2835513,))\n",
      "((100000, 24), (100000,))\n",
      "((100000, 24), (100000,))\n",
      "((100000, 24), (100000,))\n",
      "((100000, 24), (100000,))\n",
      "((100000, 24), (100000,))\n",
      "((25000, 24), (25000,))\n"
     ]
    }
   ],
   "source": [
    "_NUM_TEST_PER_CLASS = 1000\n",
    "_NUM_VAL_PER_CLASS = 4000\n",
    "_NUM_VAL_SPLITS = 5\n",
    "\n",
    "all_chroma_vectors, all_chord_labels = shuffle_set((all_chroma_vectors, all_chord_labels))\n",
    "train_split, val_splits, test_split = get_splits(all_chroma_vectors, all_chord_labels)\n",
    "\n",
    "print(train_split.shape)\n",
    "for val_split in val_splits:\n",
    "    print(val_split.shape)\n",
    "print(test_split.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3235513 100000\n",
      "3235513 100000\n",
      "3235513 100000\n",
      "3235513 100000\n",
      "3235513 100000\n"
     ]
    }
   ],
   "source": [
    "def get_next_cv_split(train_split, val_splits):\n",
    "    num_cv = len(val_splits)\n",
    "    for v_ix in range(num_cv): # index of val split at a specific round\n",
    "        addl_train_splits = val_splits[0:v_ix] + val_splits[v_ix+1:]\n",
    "        val_split = val_splits[v_ix]\n",
    "        \n",
    "        full_train_feats = np.concatenate((train_split.feats,\n",
    "                                           *[split.feats for split in addl_train_splits]))\n",
    "        full_train_labels = np.concatenate((train_split.labels,\n",
    "                                            *[split.labels for split in addl_train_splits]))\n",
    "        full_train_split = SplitData(feats=full_train_feats,labels=full_train_labels)\n",
    "        yield full_train_split, val_split\n",
    "            \n",
    "        \n",
    "for train, val in get_next_cv_split(train_split, val_splits):\n",
    "    print(len(train), len(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try with the dataloader module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded features and labels.\n",
      "Split into train, val, test.\n"
     ]
    }
   ],
   "source": [
    "from dataloader import SimpleChromaDataset\n",
    "\n",
    "ds = SimpleChromaDataset(feat_label_files=('data/01_all_chroma_vectors.npy',\n",
    "                                           'data/01_all_chord_labels.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3235513 100000\n",
      "3235513 100000\n",
      "3235513 100000\n",
      "3235513 100000\n",
      "3235513 100000\n"
     ]
    }
   ],
   "source": [
    "for train, val in ds.get_next_cv_split():\n",
    "    print(len(train), len(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cjbayron/virtualenvs/pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:7: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataloader import _CHROMA_FEAT_NAMES\n",
    "%matplotlib inline\n",
    "\n",
    "filt = [train.labels == 1] # c maj\n",
    "plt.barh(range(24), np.mean(train.feats[filt], axis=0))\n",
    "plt.yticks(range(24), _CHROMA_FEAT_NAMES)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded features and labels.\n",
      "Split into train, val, test.\n"
     ]
    }
   ],
   "source": [
    "from dataloader import SimpleChromaDataset\n",
    "\n",
    "ds = SimpleChromaDataset(feat_label_files=('data/01_all_chroma_vectors.npy',\n",
    "                                           'data/01_all_chord_labels.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Colab prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install hyperopt\n",
    "!pip install guildai # restart after install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colab prep\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp /content/drive/MyDrive/colab-handover/autochord/* ./\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import SimpleChromaDataset\n",
    "\n",
    "ds = SimpleChromaDataset(feat_label_files=('01_all_chroma_vectors.npy',\n",
    "                                           '01_all_chord_labels.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cjbayron/virtualenvs/pytorch/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n",
      "/home/cjbayron/virtualenvs/pytorch/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n",
      "/home/cjbayron/virtualenvs/pytorch/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/home/cjbayron/virtualenvs/pytorch/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from dataloader import _CHROMA_FEAT_NAMES\n",
    "\n",
    "def K_plot_loss(history):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "_SEED = 0\n",
    "_EPOCHS = 2 #10\n",
    "_BATCH_SIZE = 32 #512\n",
    "_CKPT_PATH = 'models/simple-chroma-{cv}'\n",
    "\n",
    "def init_simple_model(base_linear_units=256, dropout=0.6, opt='adam', lr=0.01):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.Input(shape=(len(_CHROMA_FEAT_NAMES),)),\n",
    "        layers.Dense(units=base_linear_units, activation='relu'),\n",
    "        layers.Dropout(rate=dropout),\n",
    "        layers.Dense(units=base_linear_units*4, activation='relu'),\n",
    "        layers.Dropout(rate=dropout),\n",
    "        layers.Dense(units=base_linear_units, activation='relu'),\n",
    "        layers.Dense(units=ds.n_class, activation='softmax'),\n",
    "    ])\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def sample_train_loop(ds):\n",
    "    # cross validation loop\n",
    "    tf.random.set_seed(_SEED)\n",
    "    for cv_ix, (train, val) in enumerate(ds.get_next_cv_split()):\n",
    "        print(f'----------- CV{cv_ix+1} -----------')\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((train.feats, train.labels)) \\\n",
    "                                       .take(100) \\\n",
    "                                       .shuffle(buffer_size=len(train), seed=_SEED, reshuffle_each_iteration=True) \\\n",
    "                                       .batch(_BATCH_SIZE)\n",
    "        val_dataset = tf.data.Dataset.from_tensor_slices((val.feats, val.labels)) \\\n",
    "                                     .take(100) \\\n",
    "                                     .shuffle(buffer_size=len(val), seed=_SEED, reshuffle_each_iteration=True) \\\n",
    "                                     .batch(_BATCH_SIZE)\n",
    "\n",
    "        print(f'Num train: {len(train)}, Num val: {len(val)}')\n",
    "        assert(train.feats.shape[-1] == val.feats.shape[-1])\n",
    "        print(f'Input features: {train.feats.shape[-1]}, Num classes: {ds.n_class}')\n",
    "        \n",
    "        model = init_simple_model()\n",
    "        history = model.fit(train_dataset, validation_data=val_dataset, epochs=_EPOCHS)\n",
    "\n",
    "        # get F1 score\n",
    "        pred_chord_ixs = np.argmax(model.predict(val.feats, batch_size=_BATCH_SIZE), axis=1)\n",
    "        print(f\"val_fscore: {f1_score(y_true=val.labels, y_pred=pred_chord_ixs, average='macro')}\")\n",
    "        K_plot_loss(history)\n",
    "\n",
    "        model.save(_CKPT_PATH.format(cv=cv_ix))\n",
    "\n",
    "        break\n",
    "\n",
    "sample_train_loop(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Manual tracking**\n",
    "\n",
    "1. 256, 0.6, `Adam (0.01)` - `val loss: 3.2, val acc: 12.98%`\n",
    "2. 1024, 0.6, `Adam (0.001)` - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automated tuning & tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colab\n",
    "!cp -R /content/drive/MyDrive/colab-handover/autochord/guild-env-colab ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>operation</th>\n",
       "      <th>started</th>\n",
       "      <th>status</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ff8c9ad6</td>\n",
       "      <td>hpset_trainloop()</td>\n",
       "      <td>2021-05-23 05:53:50</td>\n",
       "      <td>completed</td>\n",
       "      <td>bs=512 dp=0.6 hd=256 lr=0.001 opt=adam si=4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5d15565c</td>\n",
       "      <td>hpset_trainloop()</td>\n",
       "      <td>2021-05-23 05:52:48</td>\n",
       "      <td>completed</td>\n",
       "      <td>bs=512 dp=0.6 hd=256 lr=0.001 opt=adam si=3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>856f7a7f</td>\n",
       "      <td>hpset_trainloop()</td>\n",
       "      <td>2021-05-23 05:51:46</td>\n",
       "      <td>completed</td>\n",
       "      <td>bs=512 dp=0.6 hd=256 lr=0.001 opt=adam si=2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66da07ec</td>\n",
       "      <td>hpset_trainloop()</td>\n",
       "      <td>2021-05-23 05:50:44</td>\n",
       "      <td>completed</td>\n",
       "      <td>bs=512 dp=0.6 hd=256 lr=0.001 opt=adam si=1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6f21924d</td>\n",
       "      <td>hpset_trainloop()</td>\n",
       "      <td>2021-05-23 05:49:43</td>\n",
       "      <td>completed</td>\n",
       "      <td>bs=512 dp=0.6 hd=256 lr=0.001 opt=adam si=0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        run          operation             started     status  \\\n",
       "0  ff8c9ad6  hpset_trainloop() 2021-05-23 05:53:50  completed   \n",
       "1  5d15565c  hpset_trainloop() 2021-05-23 05:52:48  completed   \n",
       "2  856f7a7f  hpset_trainloop() 2021-05-23 05:51:46  completed   \n",
       "3  66da07ec  hpset_trainloop() 2021-05-23 05:50:44  completed   \n",
       "4  6f21924d  hpset_trainloop() 2021-05-23 05:49:43  completed   \n",
       "\n",
       "                                         label  \n",
       "0  bs=512 dp=0.6 hd=256 lr=0.001 opt=adam si=4  \n",
       "1  bs=512 dp=0.6 hd=256 lr=0.001 opt=adam si=3  \n",
       "2  bs=512 dp=0.6 hd=256 lr=0.001 opt=adam si=2  \n",
       "3  bs=512 dp=0.6 hd=256 lr=0.001 opt=adam si=1  \n",
       "4  bs=512 dp=0.6 hd=256 lr=0.001 opt=adam si=0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "GUILD_HOME = 'guild-env/simple-chroma' # \"guild-env-colab/simple-chroma\"\n",
    "DELETE_RUNS_ON_INIT = False\n",
    "import guild.ipy as guild\n",
    "guild.set_guild_home(GUILD_HOME)\n",
    "\n",
    "if DELETE_RUNS_ON_INIT:\n",
    "    deleted = guild.runs().delete(permanent=True)\n",
    "    print(\"Deleted %i run(s)\" % len(deleted))\n",
    "else:\n",
    "    display(guild.runs().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "_EPOCHS = 5\n",
    "_TRAIN = None\n",
    "_VAL = None\n",
    "\n",
    "# function for guild tracking\n",
    "def hpset_trainloop(hd=256, dp=0.6, opt='adam', lr=0.001, bs=512, si=0):\n",
    "    '''\n",
    "    Train loop with a specific set of hyperparams\n",
    "    \n",
    "    hd: hidden dim base size\n",
    "    dp: dropout rate\n",
    "    opt: optimizer, lr: learning rate\n",
    "    bs: batch size\n",
    "    si: CV split index\n",
    "    '''\n",
    "    tf.random.set_seed(_SEED)\n",
    "    train = _TRAIN\n",
    "    val = _VAL\n",
    "    if (not train) or (not val):\n",
    "        raise Exception(\"Missing data!\")\n",
    "    \n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((train.feats, train.labels)) \\\n",
    "                                   .take(100) \\\n",
    "                                   .shuffle(buffer_size=len(train), seed=_SEED, reshuffle_each_iteration=True) \\\n",
    "                                   .batch(bs)\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((val.feats, val.labels)) \\\n",
    "                                 .take(100) \\\n",
    "                                 .shuffle(buffer_size=len(val), seed=_SEED, reshuffle_each_iteration=True) \\\n",
    "                                 .batch(bs)\n",
    "\n",
    "    assert(train.feats.shape[-1] == val.feats.shape[-1])\n",
    "\n",
    "    model = init_simple_model(base_linear_units=hd, dropout=dp, opt=opt, lr=lr)\n",
    "    history = model.fit(train_dataset, validation_data=val_dataset, epochs=_EPOCHS, verbose=0)\n",
    "    \n",
    "    best_epoch = np.argmax(history.history['val_accuracy'])\n",
    "    best_acc = history.history['val_accuracy'][best_epoch]\n",
    "    \n",
    "    # output metrics\n",
    "    print(f\"BE: {best_epoch+1}\")\n",
    "    print(f\"VA: {best_acc}\")\n",
    "    \n",
    "    return best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning loop\n",
    "from hyperopt import hp, tpe, fmin\n",
    "\n",
    "def tuning_loop(hparams):\n",
    "    global _TRAIN\n",
    "    global _VAL\n",
    "    \n",
    "    print(hparams)\n",
    "\n",
    "    avg_acc = 0.0\n",
    "    num_runs = 0\n",
    "    for cv_ix, (train, val) in enumerate(ds.get_next_cv_split()):\n",
    "        _TRAIN = train\n",
    "        _VAL = val\n",
    "        run, acc = guild.run(hpset_trainloop,\n",
    "                             hd=int(hparams['base_hidden_dim']),\n",
    "                             dp=hparams['drop_rate'],\n",
    "                           opt=hparams['opt'],\n",
    "                             lr=hparams['lr'], \n",
    "                             bs=int(hparams['batch_size']),\n",
    "                             si=cv_ix)\n",
    "        \n",
    "        num_runs += 1\n",
    "        # if hyperparams fail miserably on one split,\n",
    "        # no need to check other splits\n",
    "        if acc < 0.5:\n",
    "            return 1.0\n",
    "            \n",
    "        avg_acc += acc\n",
    "    \n",
    "    avg_acc /= num_runs\n",
    "    return (1-avg_acc) # since we're using fmin\n",
    "\n",
    "hparams = {\n",
    "    'base_hidden_dim': hp.choice('base_hidden_dim', [256, 512, 1024]),\n",
    "    'drop_rate': hp.choice('drop_rate', [0.9, 0.7, 0.5, 0.3]),\n",
    "    'opt': hp.choice('opt', ['adam']),\n",
    "    'lr': hp.choice('lr', [1e-2, 1e-3, 3e-4, 1e-4]),\n",
    "    'batch_size': hp.choice('batch_size', [16, 32, 64]),\n",
    "}\n",
    "\n",
    "best = fmin(tuning_loop, hparams, algo=tpe.suggest, max_evals=1)\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colab\n",
    "!cp -R guild-env-colab /content/drive/MyDrive/colab-handover/autochord/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bs</th>\n",
       "      <th>dp</th>\n",
       "      <th>hd</th>\n",
       "      <th>lr</th>\n",
       "      <th>opt</th>\n",
       "      <th>si</th>\n",
       "      <th>BE</th>\n",
       "      <th>VA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>256</td>\n",
       "      <td>0.6</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>adam</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.52030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>512</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>adam</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.52078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>512</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>adam</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.52138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>256</td>\n",
       "      <td>0.5</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>adam</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.52239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>256</td>\n",
       "      <td>0.5</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>adam</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.52428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>256</td>\n",
       "      <td>0.5</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>adam</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.52686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>256</td>\n",
       "      <td>0.5</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>adam</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.52050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>256</td>\n",
       "      <td>0.5</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>adam</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.52666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     bs   dp   hd      lr   opt  si   BE       VA\n",
       "9   256  0.6  256  0.0003  adam   0  2.0  0.52030\n",
       "12  512  0.3  256  0.0003  adam   2  2.0  0.52078\n",
       "17  512  0.3  512  0.0003  adam   2  1.0  0.52138\n",
       "36  256  0.5  256  0.0001  adam   3  2.0  0.52239\n",
       "37  256  0.5  256  0.0001  adam   2  1.0  0.52428\n",
       "39  256  0.5  256  0.0001  adam   0  2.0  0.52686\n",
       "51  256  0.5  256  0.0003  adam   0  1.0  0.52050\n",
       "53  256  0.5  256  0.0001  adam   0  2.0  0.52666"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs = guild.runs()\n",
    "df_exps = runs.compare()\n",
    "\n",
    "_COMPARE_COLS = ['bs','dp','hd','lr','opt','si','BE','VA']\n",
    "comps = df_exps[_COMPARE_COLS][:65]\n",
    "comps[comps.VA > 0.52]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# try limiting class\n",
    "ds.chroma_vectors = np.load('01_all_chroma_vectors.npy')\n",
    "ds.chord_labels = np.load('01_all_chord_labels.npy')\n",
    "filt = np.isin(ds.chord_labels, (0,1))\n",
    "ds.chroma_vectors = ds.chroma_vectors[filt]\n",
    "ds.chord_labels = ds.chord_labels[filt]\n",
    "ds.classes = set(ds.chord_labels)\n",
    "ds.n_class = len(ds.classes)\n",
    "print('Loaded features and labels.')\n",
    "ds.train_split, ds.val_splits, ds.test_split = ds.get_splits()\n",
    "print('Split into train, val, test.')\n",
    "print(ds.n_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.198482  0.        0.        0.635556  0.741292  1.0043    0.81444\n",
      " 0.0292819 0.141189  0.80793   0.91015   0.823603  1.22066   0.0969013\n",
      " 0.197437  0.860228  1.16515   1.13561   0.42842   0.112475  1.49297\n",
      " 0.556156  0.562561  0.864485 ] 0\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 17\n"
     ]
    }
   ],
   "source": [
    "print(ds.chroma_vectors[0], ds.chord_labels[0])\n",
    "print(ds.chroma_vectors[-113], ds.chord_labels[-113])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cjbayron/virtualenvs/pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.32049295, 0.24610202, 0.28693406, 0.25687285, 0.20151652,\n",
       "       0.29747371, 0.20591433, 0.27151966, 0.22509008, 0.21612551,\n",
       "       0.26522816, 0.21338926, 0.7405679 , 0.48997662, 0.60600057,\n",
       "       0.60080249, 0.48543003, 0.73010563, 0.44549839, 0.73231232,\n",
       "       0.53258909, 0.54258336, 0.6778894 , 0.48055285])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filt = [ds.chord_labels == 0]\n",
    "np.mean(ds.chroma_vectors[filt], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cjbayron/virtualenvs/pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.20761943, 0.14172344, 0.25146699, 1.23340365, 0.1735976 ,\n",
       "       0.17857491, 0.14191071, 0.30587265, 0.20928596, 0.19817245,\n",
       "       0.54753261, 0.16978452, 0.48747069, 0.36887956, 0.55286642,\n",
       "       2.05746208, 0.21877638, 0.64896599, 0.25239646, 1.45968816,\n",
       "       0.40032339, 0.2984598 , 1.69132596, 0.2568249 ])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filt = [ds.chord_labels == 1]\n",
    "np.mean(ds.chroma_vectors[filt], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = [np.sum(ds.chroma_vectors, axis=1) == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cjbayron/virtualenvs/pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0: 49874,\n",
       "         2: 203,\n",
       "         8: 537,\n",
       "         22: 150,\n",
       "         13: 51,\n",
       "         6: 464,\n",
       "         7: 249,\n",
       "         12: 330,\n",
       "         9: 192,\n",
       "         4: 141,\n",
       "         24: 34,\n",
       "         1: 399,\n",
       "         17: 97,\n",
       "         15: 244,\n",
       "         10: 434,\n",
       "         5: 547,\n",
       "         14: 77,\n",
       "         3: 414,\n",
       "         11: 269,\n",
       "         20: 80,\n",
       "         18: 140,\n",
       "         23: 21,\n",
       "         16: 141,\n",
       "         19: 29,\n",
       "         21: 1})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(ds.chord_labels[filt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03958175703883171"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['loss'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 256)               6400      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              263168    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 25)                6425      \n",
      "=================================================================\n",
      "Total params: 538,393\n",
      "Trainable params: 538,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# test loading\n",
    "m = tf.keras.models.load_model(_CKPT_PATH.format(cv=0))\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add callbacks\n",
    "# add tuning\n",
    "# mind the seeding!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
